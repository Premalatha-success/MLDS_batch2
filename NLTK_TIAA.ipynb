{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c6bacafd-5cef-426a-9589-e5421b202252",
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f8c747b8-253e-4b21-bd99-aedcd29be617",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['An an valley indeed so no wonder future nature vanity.', 'Debating all she mistaken indulged believed provided declared.', 'He many kept on draw lain song as same.', 'Whether at dearest certain spirits is entered in to.', 'Rich fine bred real use too many good.', 'She compliment unaffected expression favorable any.', 'Unknown chiefly showing to conduct no.']\n",
      "['An', 'an', 'valley', 'indeed', 'so', 'no', 'wonder', 'future', 'nature', 'vanity', '.', 'Debating', 'all', 'she', 'mistaken', 'indulged', 'believed', 'provided', 'declared', '.', 'He', 'many', 'kept', 'on', 'draw', 'lain', 'song', 'as', 'same', '.', 'Whether', 'at', 'dearest', 'certain', 'spirits', 'is', 'entered', 'in', 'to', '.', 'Rich', 'fine', 'bred', 'real', 'use', 'too', 'many', 'good', '.', 'She', 'compliment', 'unaffected', 'expression', 'favorable', 'any', '.', 'Unknown', 'chiefly', 'showing', 'to', 'conduct', 'no', '.']\n"
     ]
    }
   ],
   "source": [
    "from nltk.tokenize import sent_tokenize, word_tokenize\n",
    "EXAMPLE_TEXT = \"An an valley indeed so no wonder future nature vanity. Debating all she mistaken indulged believed provided declared. He many kept on draw lain song as same. Whether at dearest certain spirits is entered in to. Rich fine bred real use too many good. She compliment unaffected expression favorable any. Unknown chiefly showing to conduct no.\"\n",
    "\n",
    "tokened_sent = sent_tokenize(EXAMPLE_TEXT)\n",
    "tokened_word = word_tokenize(EXAMPLE_TEXT)\n",
    "print(tokened_sent)\n",
    "print(tokened_word)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "375f2a23-f6bc-42d3-8af8-52b00a1eb50b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "python\n",
      "python\n",
      "python\n",
      "python\n",
      "pythonli\n"
     ]
    }
   ],
   "source": [
    "#STEMMING\n",
    "from nltk.stem import PorterStemmer\n",
    "ps = PorterStemmer()\n",
    "example_words = [\"python\",\"pythoner\",\"pythoning\",\"pythoned\",\"pythonly\"]\n",
    "for w in example_words:\n",
    " print(ps.stem(w))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c565e664-cbd7-4aa8-afc0-9aadcea8402a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "increase\n",
      "play\n",
      "play\n",
      "playing\n",
      "playing\n",
      "playing\n",
      "cat\n",
      "cactus\n",
      "goose\n",
      "rock\n",
      "python\n",
      "good\n",
      "best\n",
      "run\n",
      "run\n"
     ]
    }
   ],
   "source": [
    "from nltk.stem import WordNetLemmatizer\n",
    "lemmatizer = WordNetLemmatizer()\n",
    "print(lemmatizer.lemmatize('increases'))\n",
    "print(lemmatizer.lemmatize('playing', pos=\"v\"))\n",
    "print(lemmatizer.lemmatize('playing', pos=\"v\")) \n",
    "print(lemmatizer.lemmatize('playing', pos=\"n\")) \n",
    "print(lemmatizer.lemmatize('playing', pos=\"a\")) \n",
    "print(lemmatizer.lemmatize('playing', pos=\"r\"))\n",
    "print(lemmatizer.lemmatize(\"cats\"))\n",
    "print(lemmatizer.lemmatize(\"cacti\"))\n",
    "print(lemmatizer.lemmatize(\"geese\"))\n",
    "print(lemmatizer.lemmatize(\"rocks\"))\n",
    "print(lemmatizer.lemmatize(\"python\"))\n",
    "print(lemmatizer.lemmatize(\"better\", pos=\"a\"))\n",
    "print(lemmatizer.lemmatize(\"best\", pos=\"a\"))\n",
    "print(lemmatizer.lemmatize(\"run\"))\n",
    "print(lemmatizer.lemmatize(\"run\",'v'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "5cbfad1b-f0a4-4780-8ad6-33720b1dc610",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['This', 'sample', 'sentence', ',', 'showing', 'stop', 'words', 'filtration', '.', 'Here', 'write', 'whatever', 'want', '.', 'You', 'also', 'add', 'big', 'text', 'file', 'see', 'technique', 'works']\n"
     ]
    }
   ],
   "source": [
    "#FILTERING ALL THE STOPWORDS\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import word_tokenize\n",
    "example_sent = \"This is a sample sentence, showing off the stop words filtration. Here you can write whatever you want to. You can also add a very big text file and see how this technique works\"\n",
    "#STOP WORDS ARE PARTICULAR TO RESPECTIVE LANGUAGES(english, spanish, french Et cetera)\n",
    "stop_words = set(stopwords.words('english'))\n",
    "word_tokens = word_tokenize(example_sent)\n",
    "filtered_sentence = [w for w in word_tokens if w not in stop_words]\n",
    "\n",
    "print(filtered_sentence)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f00ccbbb-3375-4ce2-97b8-f1673a1c8f2e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "A:1\n",
      "n:29\n",
      " :55\n",
      "a:22\n",
      "v:5\n",
      "l:12\n",
      "e:39\n",
      "y:6\n",
      "i:19\n",
      "d:17\n",
      "s:14\n",
      "o:19\n",
      "w:4\n",
      "r:15\n",
      "f:6\n",
      "u:8\n",
      "t:18\n",
      ".:7\n",
      "D:1\n",
      "b:4\n",
      "g:5\n",
      "h:7\n",
      "m:6\n",
      "k:3\n",
      "p:5\n",
      "c:8\n",
      "H:1\n",
      "W:1\n",
      "R:1\n",
      "S:1\n",
      "x:1\n",
      "U:1\n"
     ]
    }
   ],
   "source": [
    "import nltk\n",
    "EXAMPLE_TEXT = \"An an valley indeed so no wonder future nature vanity. Debating all she mistaken indulged believed provided declared. He many kept on draw lain song as same. Whether at dearest certain spirits is entered in to. Rich fine bred real use too many good. She compliment unaffected expression favourable any. Unknown chiefly showing to conduct no.\"\n",
    "frequency = nltk.FreqDist(EXAMPLE_TEXT) \n",
    "for key,val in frequency.items(): \n",
    "    print (str(key) + ':' + str(val))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "e8ef2d61-5c81-4ede-a402-2d0a111332af",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "synonyms ['love.n.01', 'love.n.02', 'beloved.n.01', 'love.n.04', 'love.n.05', 'sexual_love.n.02', 'love.v.01', 'love.v.02', 'love.v.03', 'sleep_together.v.01']\n",
      "['evil', 'evilness', 'bad', 'badness', 'bad', 'evil', 'ill']\n"
     ]
    }
   ],
   "source": [
    "from nltk.corpus import wordnet\n",
    "synonyms = []\n",
    "for syns in wordnet.synsets('love'):\n",
    " synonyms.append(syns.name())\n",
    "print (\"synonyms\", synonyms)\n",
    "#FINDING ANTONYMS FROM WORDNETS\n",
    "from nltk.corpus import wordnet\n",
    "antonyms = []\n",
    "for syn in wordnet.synsets(\"good\"):\n",
    " for l in syn.lemmas():\n",
    "  if l.antonyms():\n",
    "   antonyms.append(l.antonyms()[0].name())\n",
    "print(antonyms)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "369c176d-314e-4db1-935a-45b5683c4a4c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['contact@blahblah.com', 'feedback@blah.com']\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "text = \"Please contact us at contact@blahblah.com for further information.\"+\\\n",
    "        \" You can also give feedback at feedback@blah.com\"\n",
    "\n",
    "\n",
    "emails = re.findall(r\"[a-z0-9\\.\\-+_]+@[a-z0-9\\.\\-+_]+\\.[a-z]+\", text)\n",
    "print (emails)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "472e3324",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Text from Emma by Jane Austen:\n",
      "[Emma by Jane Austen 1816]\n",
      "\n",
      "VOLUME I\n",
      "\n",
      "CHAPTER I\n",
      "\n",
      "\n",
      "Emma Woodhouse, handsome, clever, and rich, with a comfortable home\n",
      "and happy disposition, seemed to unite some of the best blessings\n",
      "of existence; and had lived nearly twenty-one years in the world\n",
      "with very little to distress or vex her.\n",
      "\n",
      "She was t\n",
      "\n",
      "Text from Hamlet by William Shakespeare:\n",
      "[The Tragedie of Hamlet by William Shakespeare 1599]\n",
      "\n",
      "\n",
      "Actus Primus. Scoena Prima.\n",
      "\n",
      "Enter Barnardo and Francisco two Centinels.\n",
      "\n",
      "  Barnardo. Who's there?\n",
      "  Fran. Nay answer me: Stand & vnfold\n",
      "your selfe\n",
      "\n",
      "   Bar. Long liue the King\n",
      "\n",
      "   Fran. Barnardo?\n",
      "  Bar. He\n",
      "\n",
      "   Fran. You come most carefully vpon \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package gutenberg to\n",
      "[nltk_data]     C:\\Users\\Premalatha\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package gutenberg is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "# Install NLTK if you haven't already: pip install nltk\n",
    "import nltk\n",
    "from nltk.corpus import gutenberg\n",
    "\n",
    "# Download the Gutenberg corpus (you only need to do this once)\n",
    "nltk.download('gutenberg')\n",
    "\n",
    "# Extract text content from different media (e.g., books from Project Gutenberg)\n",
    "emma = gutenberg.raw('austen-emma.txt')\n",
    "shakespeare = gutenberg.raw('shakespeare-hamlet.txt')\n",
    "\n",
    "print(\"Text from Emma by Jane Austen:\")\n",
    "print(emma[:300])\n",
    "\n",
    "print(\"\\nText from Hamlet by William Shakespeare:\")\n",
    "print(shakespeare[:300])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "6345728a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sentences: ['NLTK is a powerful library for natural language processing.', 'It makes it easy to work with human language data.']\n",
      "Tokens: ['NLTK', 'is', 'a', 'powerful', 'library', 'for', 'natural', 'language', 'processing', '.', 'It', 'makes', 'it', 'easy', 'to', 'work', 'with', 'human', 'language', 'data', '.']\n"
     ]
    }
   ],
   "source": [
    "import nltk\n",
    "from nltk.tokenize import sent_tokenize, word_tokenize\n",
    "\n",
    "# Sample text for sentence splitting and tokenization\n",
    "text = \"NLTK is a powerful library for natural language processing. It makes it easy to work with human language data.\"\n",
    "\n",
    "# Sentence splitting\n",
    "sentences = sent_tokenize(text)\n",
    "print(\"Sentences:\", sentences)\n",
    "\n",
    "# Tokenization\n",
    "tokens = word_tokenize(text)\n",
    "print(\"Tokens:\", tokens)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "32b46599",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Stemmed Words: ['run', 'fli', 'better', 'happili', 'cat']\n",
      "Lemmatized Words: ['running', 'fly', 'better', 'happily', 'cat']\n"
     ]
    }
   ],
   "source": [
    "from nltk.stem import PorterStemmer, WordNetLemmatizer\n",
    "\n",
    "# Sample words for stemming and lemmatization\n",
    "words = ['running', 'flies', 'better', 'happily', 'cats']\n",
    "\n",
    "# Stemming\n",
    "porter_stemmer = PorterStemmer()\n",
    "stemmed_words = [porter_stemmer.stem(word) for word in words]\n",
    "print(\"Stemmed Words:\", stemmed_words)\n",
    "\n",
    "# Lemmatization\n",
    "lemmatizer = WordNetLemmatizer()\n",
    "lemmatized_words = [lemmatizer.lemmatize(word) for word in words]\n",
    "print(\"Lemmatized Words:\", lemmatized_words)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "5cf18d75",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Filtered Tokens (after stop word removal): ['NLTK', 'powerful', 'library', 'natural', 'language', 'processing', '.', 'makes', 'easy', 'work', 'human', 'language', 'data', '.']\n"
     ]
    }
   ],
   "source": [
    "from nltk.corpus import stopwords\n",
    "\n",
    "# Sample text for stop word removal\n",
    "text = \"NLTK is a powerful library for natural language processing. It makes it easy to work with human language data.\"\n",
    "\n",
    "# Tokenization\n",
    "tokens = word_tokenize(text)\n",
    "\n",
    "# Remove stop words\n",
    "stop_words = set(stopwords.words('english'))\n",
    "filtered_tokens = [word for word in tokens if word.lower() not in stop_words]\n",
    "print(\"Filtered Tokens (after stop word removal):\", filtered_tokens)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "cd217337",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "POS Tags: [('NLTK', 'NNP'), ('is', 'VBZ'), ('a', 'DT'), ('powerful', 'JJ'), ('library', 'NN'), ('for', 'IN'), ('natural', 'JJ'), ('language', 'NN'), ('processing', 'NN'), ('.', '.'), ('It', 'PRP'), ('makes', 'VBZ'), ('it', 'PRP'), ('easy', 'JJ'), ('to', 'TO'), ('work', 'VB'), ('with', 'IN'), ('human', 'JJ'), ('language', 'NN'), ('data', 'NNS'), ('.', '.')]\n"
     ]
    }
   ],
   "source": [
    "from nltk import pos_tag\n",
    "from nltk.tokenize import word_tokenize\n",
    "\n",
    "# Sample text for POS tagging\n",
    "text = \"NLTK is a powerful library for natural language processing. It makes it easy to work with human language data.\"\n",
    "\n",
    "# Tokenization\n",
    "tokens = word_tokenize(text)\n",
    "\n",
    "# POS tagging\n",
    "pos_tags = pos_tag(tokens)\n",
    "print(\"POS Tags:\", pos_tags)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "647922a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk import RegexpParser\n",
    "from nltk.tokenize import word_tokenize\n",
    "\n",
    "# Sample text for chunking\n",
    "text = \"NLTK is a powerful library for natural language processing. It makes it easy to work with human language data.\"\n",
    "\n",
    "# Tokenization\n",
    "tokens = word_tokenize(text)\n",
    "\n",
    "# POS tagging\n",
    "pos_tags = pos_tag(tokens)\n",
    "\n",
    "# Define a chunking grammar\n",
    "grammar = r\"\"\"\n",
    "    NP: {<DT>?<JJ>*<NN>}   # Chunk NP (noun phrase)\n",
    "    PP: {<IN><NP>}         # Chunk PP (prepositional phrase)\n",
    "\"\"\"\n",
    "\n",
    "# Create a chunk parser\n",
    "chunk_parser = RegexpParser(grammar)\n",
    "\n",
    "# Perform chunking\n",
    "chunks = chunk_parser.parse(pos_tags)\n",
    "chunks.draw()  # This will open a window to display the chunks (requires Tkinter)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c3b085ce",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
